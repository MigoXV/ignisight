# @package _group_
hydra:
  run:
    dir: .

common:
  log_format: tqdm
  log_interval: 5
  wandb_project: ignisight

checkpoint:
  save_dir: outputs/test04
task:
  _name: ignisight_e2e
  # train_h5_path: data-bin/celeba/split/train.h5
  # valid_h5_path: data-bin/celeba/split/test.h5

dataset:
  num_workers: 9
  batch_size: 16

criterion:
  _name: ignisight_e2e

optimization:
  max_epoch: 20
  lr: [0.00005]

optimizer:
  _name: adam
  adam_betas: (0.9,0.98)
  adam_eps: 1e-08

lr_scheduler:
  _name: fixed

model:
  _name: tiny_bert
  base_layers: 6

distributed_training:
  distributed_world_size: 1
  ddp_backend: no_c10d
